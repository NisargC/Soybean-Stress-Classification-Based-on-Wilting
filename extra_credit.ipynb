{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extra_credit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CifCHZrfyrXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD1fuu7yywnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd\n",
        "%cd \"/content/drive/My Drive/c_p/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG0YZ1ONy1J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rn\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "rn.seed(12345)\n",
        "!nvidia-smi\n",
        "# %load_ext tensorboard\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto() \n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "import cv2\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Lambda, multiply, ReLU, LeakyReLU, MaxPooling2D,MaxPool2D, GaussianNoise, GlobalMaxPooling2D, GlobalAveragePooling2D,  SpatialDropout2D,  Flatten, BatchNormalization, concatenate, Input, Activation, Average, AveragePooling2D\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import argparse\n",
        "from sklearn import tree\n",
        "import keras\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from keras.utils import to_categorical\n",
        "import datetime\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import pandas as pd\n",
        "print(\"Imported\")\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kb8LqTumyvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cE62Lswmq13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from helper import Helper\n",
        "# helper = Helper(mode='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjH1bzmpmzjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(0, 100):\n",
        "#     if helper.Y_train[i] == 4:\n",
        "#         plt.figure(dpi=200)\n",
        "#         plt.imshow(cv2.cvtColor(helper.X_train_images[i], cv2.COLOR_BGR2RGB))\n",
        "#         plt.title(helper.Y_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RCCZAJky-Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data_set(path, img_path, means=None, stds=None):\n",
        "\n",
        "    \n",
        "    df = pd.read_csv(path, index_col=None)\n",
        "    file_names = df['file_name']\n",
        "    Y = df['annotation']\n",
        "    df = df.drop(columns=['file_name', 'annotation'])\n",
        "    features = df.values\n",
        "    features = features.copy().T\n",
        "    normalized_features = []\n",
        "    train_means = []\n",
        "    train_std = []\n",
        "    for i, feature in enumerate(features):\n",
        "        m = None\n",
        "        std = None\n",
        "        if means is None:\n",
        "            m = np.mean(feature)\n",
        "            std = np.std(feature)\n",
        "            train_means.append(m)\n",
        "            train_std.append(std)\n",
        "        else:\n",
        "            m = means[i]\n",
        "            std = stds[i]\n",
        "        feature -= m\n",
        "        feature /= std\n",
        "        normalized_features.append(feature)\n",
        "    normalized_features = np.array(normalized_features).T\n",
        "    print(normalized_features.shape)\n",
        "    X_images = []\n",
        "\n",
        "    for file in tqdm(file_names):\n",
        "        img = cv2.imread(img_path + file)\n",
        "        img = cv2.resize(img, (224, 224), cv2.INTER_CUBIC)\n",
        "        X_images.append(img.astype('float32')/255)\n",
        "\n",
        "    return np.array(X_images).astype('float32'), normalized_features, np.array(to_categorical(Y)), train_means, train_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6xPh_EO-v11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(Y, Y_pred):\n",
        "    total = len(Y)\n",
        "    if len(Y) != len(Y_pred):\n",
        "        print(\"Shapes for predictions and ground truth don't match\")\n",
        "        return\n",
        "    correct = sum([int(Y_pred[i] == Y[i]) for i in range(total)])\n",
        "    return correct * 100 / total\n",
        "from sklearn.metrics import mean_squared_error, classification_report\n",
        "def eval(pred, gt):\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    accuracy = calc_accuracy(gt, list(pred))\n",
        "    mse = mean_squared_error(gt, list(pred))\n",
        "    print(\"Classification report for - \\n{}:\\n{}\\n\".format(None, metrics.classification_report(gt, list(pred))))\n",
        "    print(\"MSE = \" + str(mse))\n",
        "    print(\"Accuracy = \" + str(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yas--ByP0elH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_images_train, X_features_train, Y_train, train_means, train_std = read_data_set('./data/ExtraCredit_Train.csv', './data/TrainData/', None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWRLYRh5ylL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_features_train[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBZuyiqc0kmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_images_test, X_features_test, Y_test, _, _ = read_data_set('./data/ExtraCredit_Test.csv', './data/TrainData/', train_means, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZztKAMug6fxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBexE4TtlU-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_features_channel(X_features):\n",
        "    channels = []\n",
        "    dim_x, dim_y = 32, 32\n",
        "    break_x = int(dim_x/4)\n",
        "    break_y = int(dim_y/3)\n",
        "    for x in X_features:\n",
        "        r = np.zeros((dim_x, dim_y))\n",
        "        f_ind = 0\n",
        "\n",
        "        for i in range(4):\n",
        "            for j in range(3):\n",
        "                r[j * break_y: (j+1) * break_y, i * break_x: (i+1) * break_x] = x[f_ind]\n",
        "                f_ind += 1\n",
        "\n",
        "        g = np.zeros((dim_x, dim_y))\n",
        "        f_ind = 0\n",
        "\n",
        "        for i in range(3):\n",
        "            for j in range(4):\n",
        "                g[j * break_x: (j+1) * break_x, i * break_y: (i+1) * break_y] = x[f_ind]\n",
        "                f_ind += 1\n",
        "\n",
        "        b = np.zeros((dim_x, dim_y))\n",
        "        f_ind = 0\n",
        "\n",
        "        for j in range(3, -1, -1):\n",
        "            for i in range(3):\n",
        "                b[j * break_x: (j+1) * break_x, i * break_y: (i+1) * break_y] = x[f_ind]\n",
        "                f_ind += 1\n",
        "\n",
        "        channel = cv2.merge((r, g, b)).astype('float32')\n",
        "        channels.append(channel)\n",
        "    return np.array(channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuJM7_M7mvnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_channel_features_train = create_features_channel(X_features_train)\n",
        "X_channel_features_test = create_features_channel(X_features_test)\n",
        "print(X_channel_features_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEQALuoH4EbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_1():\n",
        "    # activity_regularizer = None\n",
        "    activity_regularizer = regularizers.l2(0.00001)\n",
        "    base_activity_regularizer = regularizers.l1(0.0001)\n",
        "\n",
        "    features = Input(shape=(12, ))\n",
        "    # x = Dense(12, activation='relu', activity_regularizer=None)(features)\n",
        "    # x = GaussianNoise(0.001)(features)\n",
        "    x = Dense(1000, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(features)\n",
        "    # x = Dropout(0.1)(x)\n",
        "    x = Dense(180, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    # x = Dropout(0.1)(x)\n",
        "    x = Dense(12, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    \n",
        "    # x = GaussianNoise(0.04)(x)\n",
        "    # x = Dense(120, activation='relu', activity_regularizer=None)(x)\n",
        "    # x = Dense(12, activation='relu', activity_regularizer=None)(x)\n",
        "    # x = Dense(12, activation='relu', activity_regularizer=None)(x)\n",
        "    # x = Dropout(0.5)(x)\n",
        "    y = GaussianNoise(0.075)(features)\n",
        "    # y = Dense(12, activation='relu', activity_regularizer=None, bias_regularizer=None)(y)\n",
        "    \n",
        "    x = Dense(5, activation='softmax', bias_regularizer=None)(concatenate([x, y]))\n",
        "    model = Model(features, x)\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8TVH_We8r_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_weather = model_1()\n",
        "model_weather.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "model_weather.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(cnn_model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEevT-tkn6vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_weather.fit(X_features_train, Y_train, validation_data=(X_features_test, Y_test), epochs=200,  verbose=1, class_weight=class_weights, callbacks=callbacks, shuffle=True, batch_size=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvwqZt3FkPjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather_only_pred = model_weather.predict(X_features_test)\n",
        "print(list(np.argmax(weather_only_pred, axis=1)))\n",
        "eval(weather_only_pred, list(np.argmax(Y_test, axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2rl2CcSRUx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(dpi=200)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WOAY75mJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_data_generator = ImageDataGenerator(fill_mode='reflect', rotation_range=15, channel_shift_range=0.2, brightness_range=[0.5, 1.3], horizontal_flip=True, vertical_flip=True, zoom_range=[0.5, 1], dtype='float32', rescale=1./255, samplewise_center=True, samplewise_std_normalization=True)\n",
        "test_data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True, rescale=1./255)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TNSimXF63IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=5, restore_best_weights=True)\n",
        "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
        "callbacks = [es]\n",
        "class_counts = Counter(list(np.argmax(Y_train, axis=1)))\n",
        "class_weights = {}\n",
        "sub_total = len(list(Y_train))/2\n",
        "for i in range(5):\n",
        "    class_weights[i] = ((sub_total / class_counts[i]) + 5) / 6\n",
        "print(\"Final weights = \" + str(class_weights) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy8Wbb1BlbO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_2():\n",
        "    # activity_regularizer = None\n",
        "    top_regularizer = regularizers.l2(0.001)\n",
        "    activity_regularizer = regularizers.l1(0.01)\n",
        "\n",
        "\n",
        "    base = tf.keras.applications.MobileNet(include_top=False)\n",
        "\n",
        "\n",
        "    for layer in base.layers:\n",
        "      for attr in ['activity_regularizer']:\n",
        "        if hasattr(layer, attr):\n",
        "          # print(attr)\n",
        "          setattr(layer, attr, activity_regularizer)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalMaxPooling2D()(x)\n",
        "    # x = GaussianNoise(0.1)(x)\n",
        "    # x = Dropout(0.8)(x)\n",
        "    x = Dense(300, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    # x = Dropout(0.3)(x)\n",
        "    x = Dense(100, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "\n",
        "    # y = GaussianNoise(0.075)(features)\n",
        "    # y = Dense(12, activation='relu', activity_regularizer=None, bias_regularizer=None)(y)\n",
        "    \n",
        "    x = Dense(5, activation='softmax', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    model = Model(base.input, x)\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaXIslInCLsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model = model_2()\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.00005), metrics=['accuracy'])\n",
        "cnn_model.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(cnn_model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7OFhVi5pJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# train = train_data_generator.flow(X_images_train, Y_train, batch_size=40, shuffle=True)\n",
        "# test = test_data_generator.flow(X_images_test, Y_test, batch_size=25, shuffle=False)\n",
        "history = cnn_model.fit(X_images_train, Y_train, validation_data=(X_images_test, Y_test), epochs=200,  verbose=1, class_weight=class_weights, callbacks=callbacks, shuffle=True, batch_size=40, validation_steps=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YilJDS4598I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pred_cnn_only = cnn_model.predict(X_images_test)\n",
        "print(list(np.argmax(pred_cnn_only, axis=1)))\n",
        "eval(pred_cnn_only, list(np.argmax(Y_test, axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oonedDduCWCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(dpi=200)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weonwtqkMJOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensemble():\n",
        "\n",
        "\n",
        "    # activity_regularizer = None\n",
        "    activity_regularizer = regularizers.l2(0.00001)\n",
        "    base_activity_regularizer = regularizers.l1(0.0001)\n",
        "\n",
        "    features = Input(shape=(12, ))\n",
        "    a = Dense(1000, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(features)\n",
        "\n",
        "    a = Dense(180, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(a)\n",
        "\n",
        "    a = Dense(12, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(a)\n",
        "\n",
        "    b = GaussianNoise(0.075)(features)\n",
        "    # y = Dense(12, activation='relu', activity_regularizer=None, bias_regularizer=None)(y)\n",
        "    \n",
        "    out_1 = Dense(5, activation='relu', bias_regularizer=None)(concatenate([a, b]))\n",
        "\n",
        "\n",
        "    # activity_regularizer = None\n",
        "    top_regularizer = regularizers.l2(0.003)\n",
        "    activity_regularizer = regularizers.l2(0.01)\n",
        "\n",
        "\n",
        "    base = tf.keras.applications.MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "    for layer in base.layers:\n",
        "      for attr in ['activity_regularizer']:\n",
        "        if hasattr(layer, attr):\n",
        "          # print(attr)\n",
        "          setattr(layer, attr, activity_regularizer)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalMaxPooling2D()(x)\n",
        "    # x = GaussianNoise(0.1)(x)\n",
        "    # x = Dropout(0.1)(x)\n",
        "    x = Dense(300, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    # x = Dropout(0.3)(x)\n",
        "    x = Dense(100, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "\n",
        "    # y = GaussianNoise(0.075)(features)\n",
        "    # y = Dense(12, activation='relu', activity_regularizer=None, bias_regularizer=None)(y)\n",
        "    \n",
        "    out_2 = Dense(5, activation='relu', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(x)\n",
        "\n",
        "    pred = Dense(5, activation='softmax', activity_regularizer=activity_regularizer, bias_regularizer=activity_regularizer)(concatenate([out_1, out_2]))\n",
        "\n",
        "    model = Model([base.input, features], pred)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_sGRg2cbBu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensmble_model = ensemble()\n",
        "ensmble_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "# ensmble_model.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(ensmble, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQrEgf8kD4Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_1 = ensmble_model.fit([X_images_train, X_features_train], Y_train, validation_data=([X_images_test, X_features_test], Y_test), epochs=200,  verbose=1, class_weight=class_weights, callbacks=callbacks, shuffle=True, batch_size=40, validation_steps=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_L34bulQvkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pred_combined_only = ensmble_model.predict([X_images_test, X_features_test])\n",
        "\n",
        "print(list(np.argmax(pred_combined_only, axis=1)))\n",
        "eval(pred_combined_only, list(np.argmax(Y_test, axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP09yC44SOXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(dpi=200)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ry7wLzSQx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}