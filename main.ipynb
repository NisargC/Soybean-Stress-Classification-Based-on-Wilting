{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "binary_tree_ensemble",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "LtPAFmdS8ymL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW-B24X19jeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd\n",
        "%cd \"/content/drive/My Drive/c_p/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQGWoLN9VfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rn\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "rn.seed(12345)\n",
        "!nvidia-smi\n",
        "%load_ext tensorboard\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto() \n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "import cv2\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Lambda, multiply, ReLU, LeakyReLU, MaxPooling2D,MaxPool2D, GlobalMaxPooling2D, GlobalAveragePooling2D,  SpatialDropout2D,  Flatten, BatchNormalization, concatenate, Input, Activation, Average, AveragePooling2D\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from helper import Helper\n",
        "import argparse\n",
        "from sklearn import tree\n",
        "import keras\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from keras_model import Keras_model\n",
        "from sklearn_model import Sklearn_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from collections import Counter\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from keras.utils import to_categorical\n",
        "import datetime\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "print(\"Imported\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "scrolled": false,
        "id": "qP-iGU828ymT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "helper = Helper(mode='all', img_resize=[480, 360])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mD7Ysn7mSfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # for i in range(100, 200):\n",
        "# #   if helper.Y_train[i] == 0:\n",
        "# for i, img in enumerate(helper.X_train_images[:50]):\n",
        "#     if helper.Y_train[i] == 3:\n",
        "#       plt.figure(dpi=200)\n",
        "#       plt.imshow(helper.X_train_images[i])\n",
        "#       plt.title(helper.Y_train[i])\n",
        "#       plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr_G9Oz_R1i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras import backend as K\n",
        "def categorical_focal_loss(gamma=2., alpha=.25):\n",
        "    \"\"\"\n",
        "    Softmax version of focal loss.\n",
        "           m\n",
        "      FL = âˆ‘  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
        "          c=1\n",
        "      where m = number of classes, c = class and o = observation\n",
        "    Parameters:\n",
        "      alpha -- the same as weighing factor in balanced cross entropy\n",
        "      gamma -- focusing parameter for modulating factor (1-p)\n",
        "    Default value:\n",
        "      gamma -- 2.0 as mentioned in the paper\n",
        "      alpha -- 0.25 as mentioned in the paper\n",
        "    References:\n",
        "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
        "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
        "    Usage:\n",
        "     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred: A tensor resulting from a softmax\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        # Scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "\n",
        "        # Clip the prediction value to prevent NaN's and Inf's\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Calculate Cross Entropy\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Calculate Focal Loss\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        # Sum the losses in mini_batch\n",
        "        return K.sum(loss, axis=1)\n",
        "\n",
        "    return categorical_focal_loss_fixed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pevK4_SdjA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def mse_and_crossentropy():\n",
        "    def loss(y_true, y_pred):\n",
        "        loss_cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "        loss_mse = tf.keras.losses.MSE(K.cast(K.argmax(y_true, axis=1), dtype=tf.float32), K.cast(K.argmax(y_pred, axis=1), dtype=tf.float32))\n",
        "        return loss_mse + loss_cce\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gRHsbDcntpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xcept(output_bias, regularization=None, classes=5):\n",
        "    if output_bias is not None:\n",
        "      output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "    regularizer = None\n",
        "    dropout_regularizer = None\n",
        "    if regularization:\n",
        "      prediction_regularizer = regularizers.l2(regularization[1] * 35)\n",
        "      prediction_bias_regularizer = regularizers.l1(regularization[0])\n",
        "      \n",
        "      regularizer = regularizers.l2(regularization[1])\n",
        "      bias_regularizer = regularizers.l1(regularization[0])\n",
        "\n",
        "      activity_regularizer = regularizers.l2(regularization[1])\n",
        "      prediction_activity_regularizer = regularizers.l2(regularization[1] * 50)\n",
        "\n",
        "      sparsity = regularizers.l1(regularization[0])\n",
        "\n",
        "    input_image = Input(shape=(299, 299, 3))\n",
        "    base_model = tf.keras.applications.Xception(input_tensor=input_image, include_top=False)\n",
        "    base_model._name = 'm1'\n",
        "    print(\"xcpt\")\n",
        "    another_base_model = tf.keras.applications.MobileNetV2(input_tensor=input_image, include_top=False)\n",
        "    another_base_model._name = 'm2'\n",
        "    print(\"mb\")\n",
        "\n",
        "    # for layer in base_model.layers[:int(len(base_model.layers) * 0.75)]:\n",
        "    #   layer.trainable = False\n",
        "\n",
        "    # for layer in another_base_model.layers[:int(len(another_base_model.layers) * 0.7)]:\n",
        "    #   layer.trainable = False\n",
        "\n",
        "    # for layer in base_model.layers:\n",
        "    #   for attr in ['kernel_regularizer']:\n",
        "    #     if hasattr(layer, attr):\n",
        "    #       # print(attr)\n",
        "    #       setattr(layer, attr, regularizer)\n",
        "    \n",
        "    # for layer in base_model.layers:\n",
        "    #   for attr in ['bias_regularizer']:\n",
        "    #     if hasattr(layer, attr):\n",
        "    #       # print(attr)\n",
        "    #       setattr(layer, attr, bias_regularizer)\n",
        "\n",
        "    # for layer in another_base_model.layers:\n",
        "    #   for attr in ['kernel_regularizer']:\n",
        "    #     if hasattr(layer, attr):\n",
        "    #       # print(attr)\n",
        "    #       setattr(layer, attr, regularizer)\n",
        "    \n",
        "    # for layer in another_base_model.layers:\n",
        "    #   for attr in ['bias_regularizer']:\n",
        "    #     if hasattr(layer, attr):\n",
        "    #       # print(attr)\n",
        "    #       setattr(layer, attr, bias_regularizer)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "      for attr in ['activity_regularizer']:\n",
        "        if hasattr(layer, attr):\n",
        "          # print(attr)\n",
        "          setattr(layer, attr, sparsity)\n",
        "    \n",
        "    for layer in another_base_model.layers:\n",
        "      for attr in ['activity_regularizer']:\n",
        "        if hasattr(layer, attr):\n",
        "          # print(attr)\n",
        "          setattr(layer, attr, sparsity)\n",
        "\n",
        "    y = another_base_model.output\n",
        "    y = GlobalAveragePooling2D()(y)\n",
        "    y = Dropout(0.4)(y)\n",
        "    y = Dense(512, activation=LeakyReLU(alpha=0.1), activity_regularizer=activity_regularizer)(y)\n",
        "    y = Dropout(0.3)(y)\n",
        "    y = Dense(100, activation=LeakyReLU(alpha=0.1), activity_regularizer=activity_regularizer)(y)\n",
        "    y = Dropout(0.2)(y)\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(512, activation=LeakyReLU(alpha=0.1), activity_regularizer=activity_regularizer)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(100, activation=LeakyReLU(alpha=0.1), activity_regularizer=activity_regularizer)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # model_1 = Model(input_image, x)\n",
        "    # model_1.summary()\n",
        "    # model_2 = Model(base_model.input, y)\n",
        "    # model_1.summary()\n",
        "    z = Dense(64, activation=LeakyReLU(alpha=0.1), activity_regularizer=activity_regularizer)(concatenate([x, y]))\n",
        "    # z = Dropout(0.3)(z)\n",
        "\n",
        "    predictions = Dense(classes, activation='softmax', activity_regularizer=prediction_activity_regularizer, bias_initializer=output_bias)(z)\n",
        "\n",
        "    # add your top layer block to your base model\n",
        "    model = Model(input_image, predictions)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZykG8RBX1qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initial_bias = np.log([pos/neg])\n",
        "counts = Counter(helper.Y_train)\n",
        "total = len(list(helper.Y_train))\n",
        "bias_factors = []\n",
        "for i in range(5):\n",
        "    bias_factors.append(counts[i] / (total - counts[i]))\n",
        "initial_bias = np.log(bias_factors)\n",
        "print(initial_bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYGnK7v7fsDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arch = xcept(initial_bias, [0.01, 0.001], classes=5)\n",
        "# arch.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(arch, to_file='model.png', dpi=300, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-V0UVlgdE6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(helper.X_train_images)\n",
        "Y = np.array(helper.Y_train)\n",
        "model = Keras_model(helper, arch, use_data_gen=True, is_cnn=True, early_stopping_patience=3, show_summary = False, epochs=34, validation_split=0.15, early_stopping=True, early_stopping_metric='val_loss', k_fold_splits = 4, optimizer = optimizers.Adam(learning_rate=0.00006), batch_size=32, verbose=1)\n",
        "X_val, Y_val = model.fit(X, Y, [[299, 299], [500, 400, 360, 360, 400], [162, 162, 162, 162, 162]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "872FpZiSPNlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(dpi=200)\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GZQ1_BwEHov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.model.save('./model_multi_tl_hsv',  overwrite=True, save_format='tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKwoltHPIEfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('X_train', model.X_train, allow_pickle=True)\n",
        "np.save('X_val', model.X_val, allow_pickle=True)\n",
        "np.save('Y_train', model.Y_train, allow_pickle=True)\n",
        "np.save('Y_val', model.Y_val, allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-IuzUIx3wQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load('X_train.npy', allow_pickle=True)\n",
        "X_val = np.load('X_val.npy', allow_pickle=True)\n",
        "Y_train = np.load('Y_train.npy', allow_pickle=True)\n",
        "Y_val = np.load('Y_val.npy', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJQAoF50SGhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('./model_multi_tl_hsv', compile=False)\n",
        "loaded_model.compile(loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0kElFaYH-4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import mean_squared_error, classification_report\n",
        "# from keras_preprocessing.image import ImageDataGenerator\n",
        "# data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "# data_generator.fit(X_val)\n",
        "# print(X_val.shape)\n",
        "# val_pred = np.argmax(loaded_model.predict(data_generator.flow(X_val, shuffle=False, batch_size=76), steps=10), axis=1)\n",
        "# print(val_pred)\n",
        "# print(Y_val.shape)\n",
        "# accuracy = helper.calc_accuracy(list(np.argmax(Y_val, axis=1)), list(val_pred))\n",
        "# mse = mean_squared_error(list(np.argmax(Y_val, axis=1)), list(val_pred))\n",
        "# print(\"Classification report for - \\n{}:\\n{}\\n\".format(loaded_model, metrics.classification_report(list(np.argmax(Y_val, axis=1)), list(val_pred))))\n",
        "# print(mse)\n",
        "# print(accuracy)\n",
        "# print(Counter(val_pred))\n",
        "# print(accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIIYSTgf8NEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import mean_squared_error, classification_report\n",
        "# from keras_preprocessing.image import ImageDataGenerator\n",
        "# X_train_0 = crop_test(helper.X_train_images[0:500], [299, 299])\n",
        "# X_train_1 = crop_test(helper.X_train_images[500:1000], [299, 299])\n",
        "# X_train_2 = crop_test(helper.X_train_images[1000:], [299, 299])\n",
        "\n",
        "\n",
        "# data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "# data_generator.fit(X_train_0)\n",
        "# softmax_0 = loaded_model.predict(data_generator.flow(X_train_0, shuffle=False, batch_size=100), steps=25)\n",
        "\n",
        "# data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "# data_generator.fit(X_train_1)\n",
        "# softmax_1 = loaded_model.predict(data_generator.flow(X_train_1, shuffle=False, batch_size=100), steps=25)\n",
        "# print(X_train_2.shape)\n",
        "\n",
        "# data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "# data_generator.fit(X_train_2)\n",
        "# softmax_test = loaded_model.predict(data_generator.flow(X_train_2, shuffle=False, batch_size=125), steps=11)\n",
        "\n",
        "y_true_0 = helper.Y_train[0:500]\n",
        "y_true_1 = helper.Y_train[500:1000]\n",
        "y_true_test = helper.Y_train[1000:]\n",
        "\n",
        "softmax_all = np.concatenate([softmax_0, softmax_1, softmax_test])\n",
        "y_true = np.concatenate([y_true_0, y_true_1, y_true_test])\n",
        "\n",
        "\n",
        "print(softmax_all.shape)\n",
        "print(y_true.shape)\n",
        "results = ensemble_decision(softmax_all)\n",
        "print(len(results))\n",
        "\n",
        "accuracy = helper.calc_accuracy(y_true, list(results))\n",
        "mse = mean_squared_error(y_true, results)\n",
        "print(\"Classification report for - \\n{}:\\n{}\\n\".format(loaded_model, metrics.classification_report(y_true, results)))\n",
        "print(mse)\n",
        "print(accuracy)\n",
        "print(results)\n",
        "print(Counter(results))\n",
        "print(accuracy)\n",
        "# print(len(softmax_5))\n",
        "# dont_forget = [softmax_5, y_true]\n",
        "print(X_train_0.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpoWlH2IUfmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "def decision_clf(softmax, y_true):\n",
        "  regr = RandomForestRegressor(random_state=0)\n",
        "  regr.fit(softmax, y_true)\n",
        "\n",
        "  print(regr.feature_importances_)  \n",
        "  return regr\n",
        "\n",
        "def check_decision_clf(all_preds, index, y_true):\n",
        "    global k\n",
        "    k = 0\n",
        "    softmax = []\n",
        "    ind = []\n",
        "    for i in range(index, len(all_preds), 5):\n",
        "        softmax.append(all_preds[i:i+5].flatten())\n",
        "        ind.append(i)\n",
        "    print(ind)\n",
        "    regr = decision_clf(softmax, y_true)\n",
        "    pred = np.round(regr.predict(softmax)).astype('int')\n",
        "    print(pred)\n",
        "    acc = helper.calc_accuracy(y_true, list(pred))\n",
        "    print(acc)\n",
        "    return regr\n",
        "\n",
        "c_0 = check_decision_clf(softmax_all, 0, y_true)\n",
        "\n",
        "def ensemble_decision(softmax_5):\n",
        "\n",
        "    softmax = []\n",
        "    for i in range(0, len(softmax_5), 5):\n",
        "          softmax.append(softmax_5[i:i+5].flatten())\n",
        "    pred = np.round(c_0.predict(softmax)).astype('int')\n",
        "    return pred\n",
        "\n",
        "# c_1 = check_classifer(softmax_5, 1, y_true)\n",
        "# # print(c_1)\n",
        "# c_2 = check_classifer(softmax_5, 2, y_true)\n",
        "# # print(c_2)\n",
        "# c_3 = check_classifer(softmax_5, 3, y_true)\n",
        "# # print(c_3)\n",
        "# c_4 = check_classifer(softmax_5, 4, y_true)\n",
        "# # print(c_4)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhNtcAkEPFEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(thresholds, softmax, y_true, k):\n",
        "    softmax = np.array(softmax)\n",
        "    total = np.array(y_true).shape[0]\n",
        "    correct = 0\n",
        "    if total != softmax.shape[0]:\n",
        "      print(\"unequal y ypred\")\n",
        "    for i, y in enumerate(softmax):\n",
        "        # print(len(y))\n",
        "        factor = 0\n",
        "        volume = 0\n",
        "        most_confident = np.argmax(y)\n",
        "        for c in range(5):\n",
        "            volume += (y[c] * thresholds[most_confident * 5 + c]) * c\n",
        "            factor = (y[c] * thresholds[most_confident * 5 + c])\n",
        "        if (int(round(volume/factor)) == y_true[i]): correct += 1\n",
        "    # print(correct)\n",
        "    return -1 * (correct)\n",
        "\n",
        "bounds = [(-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kNsxaetVAIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from scipy.optimize import differential_evolution\n",
        "def check_classifer(all_preds, index, y_true):\n",
        "    global k\n",
        "    k = 0\n",
        "    softmax = []\n",
        "    ind = []\n",
        "    for i in range(index, len(all_preds), 5):\n",
        "        softmax.append(all_preds[i])\n",
        "        ind.append(i)\n",
        "    print(ind)\n",
        "    return differential_evolution(calc_accuracy, bounds, args=(softmax, y_true, k))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7rVaG4KZug_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_0 = check_classifer(softmax_5, 0, y_true)\n",
        "print(c_0)\n",
        "# c_1 = check_classifer(softmax_5, 1, y_true)\n",
        "# print(c_1)\n",
        "# c_2 = check_classifer(softmax_5, 2, y_true)\n",
        "# print(c_2)\n",
        "# c_3 = check_classifer(softmax_5, 3, y_true)\n",
        "# print(c_3)\n",
        "# c_4 = check_classifer(softmax_5, 4, y_true)\n",
        "# print(c_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Ypts7j5A_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import mean_squared_error\n",
        "# from keras_preprocessing.image import ImageDataGenerator\n",
        "# data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "# data_generator.fit(model.X_train)\n",
        "print(len(model.X_train))\n",
        "# # softmax_5 = loaded_model.predict(data_generator.flow(X_train, shuffle=False, batch_size=75), steps=len(X_train/75))\n",
        "model_train_pred = model.model.predict(data_generator.flow(model.X_train, shuffle=False, batch_size=100), steps=len(model.X_train/100) + 1)\n",
        "\n",
        "# model.print_classification_report(np.argmax(model.Y_train, axis=1), model_train_pred)\n",
        "# accuracy = helper.calc_accuracy(np.argmax(model.Y_train, axis=1), list(model_train_pred))\n",
        "# mse = mean_squared_error(np.argmax(model.Y_train, axis=1), model_train_pred)\n",
        "# print(mse)\n",
        "# print(model_train_pred)\n",
        "# print(accuracy)\n",
        "# print(Counter(model_train_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvmGcqlahZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_th = [c_0.x, c_1.x, c_2.x, c_3.x, c_4.x]\n",
        "def classify(thresholds, softmax):\n",
        "    softmax = np.array(softmax)\n",
        "    votes = []\n",
        "    for i, y in enumerate(softmax):\n",
        "        factor = 0\n",
        "        volume = 0\n",
        "        for c in range(5):\n",
        "            volume += (y[c] - thresholds[c]) * i\n",
        "            factor = (y[c] - thresholds[c])\n",
        "        votes.append(int(round(volume/factor)) == y_true[i])\n",
        "            \n",
        "    # print(correct)\n",
        "    return votes\n",
        "\n",
        "def predict_ensemble(all_softmax_5):\n",
        "    results = []\n",
        "    votes = []\n",
        "    for index in range(5):\n",
        "      softmax = []\n",
        "      for i in range(index, len(all_softmax_5), 5):\n",
        "          softmax.append(all_softmax_5[i])\n",
        "      votes_i = classify(all_th[index], softmax)\n",
        "      # print(votes_i)\n",
        "      votes.append(votes_i)\n",
        "    print(votes)\n",
        "\n",
        "    for i in range(0, int(len(softmax))):\n",
        "        print(i)\n",
        "        sample_votes = []\n",
        "        for c in range(5):\n",
        "          sample_votes.append(votes[c][i])\n",
        "        vote_count = np.bincount(sample_votes)\n",
        "        choice = np.argmax(vote_count)\n",
        "        # print(choice)\n",
        "        results.append(choice)\n",
        "    return results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDqPi5F-U9ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2oHfAE37iGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ggArtsdOf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras_preprocessing.image import ImageDataGenerator\n",
        "# data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "# pred_val = model.model.predict(data_generator.flow(model.X_val, model.Y_val, shuffle=False, batch_size=100), steps=10)\n",
        "model.print_classification_report(np.argmax(model.Y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "accuracy = helper.calc_accuracy(np.argmax(model.Y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "mse = mean_squared_error(np.argmax(model.Y_val, axis=1), np.argmax(pred_val, axis=1))\n",
        "print(mse)\n",
        "print(accuracy)\n",
        "print(Counter(np.argmax(pred_val, axis=1)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki36tEHynywB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzgeM8A6ndcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, classification_report\n",
        "X_train = crop_test(helper.X_train_images, dim=[299, 299])\n",
        "pred = loaded_model.predict_classes(X_train[:100])\n",
        "print(helper.Y_train)\n",
        "results = predict_cropped_test_max(pred)\n",
        "accuracy = helper.calc_accuracy(helper.Y_train[:100], list(results))\n",
        "mse = mean_squared_error(helper.Y_train[:100], results)\n",
        "print(\"Classification report for - \\n{}:\\n{}\\n\".format(model, metrics.classification_report(helper.Y_train[:100], results)))\n",
        "print(mse)\n",
        "print(accuracy)\n",
        "print(results[:100])\n",
        "print(Counter(results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBMp3aVemDLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "data_generator = ImageDataGenerator(dtype='float32', samplewise_center=True, samplewise_std_normalization=True)\n",
        "\n",
        "# X_test = crop_test(helper.X_test_images, dim=[299, 299])\n",
        "# data_generator.fit(X_test)\n",
        "# pred = model.model.predict(data_generator.flow(X_test, shuffle=False, batch_size=100), steps=10)\n",
        "\n",
        "results = predict_ensemble(pred)\n",
        "print(results)\n",
        "print(Counter(results))\n",
        "\n",
        "# pred_1, pred_2, pred_3, pred_4  = predict_cropped_test(pred)\n",
        "# print(pred_1)\n",
        "# print(Counter(pred_1))\n",
        "# print(pred_2)\n",
        "# print(Counter(pred_2))\n",
        "# print(pred_3)\n",
        "# print(Counter(pred_3))\n",
        "# print(pred_4)\n",
        "# print(Counter(pred_4))\n",
        "# voted_predictions = helper.one_hot_transform(helper.one_hot, results)\n",
        "# np.savetxt(\"predict.csv\", voted_predictions, delimiter=\",\", fmt='%i')\n",
        "# print(voted_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNmpORzCUTIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "for i, img in enumerate(helper.X_test_images):\n",
        "  if results[i] == 4:\n",
        "    plt.figure(dpi=200)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_HSV2RGB))\n",
        "    plt.title(str(results[i]) + \"   \" + str(i))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QapUuz5TlJTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "def crop_test(X, dim):\n",
        "    data = []\n",
        "    original_dim_x = X[0].shape[1]\n",
        "    original_dim_y = X[0].shape[0]\n",
        "    mid_start_x = int((original_dim_x - dim[0])/2)\n",
        "    mid_start_y = int((original_dim_y - dim[1]) / 2)\n",
        "    for x in X:\n",
        "        data.append(x[:dim[1], :dim[0]])\n",
        "        data.append(x[-dim[1]:, -dim[0]:])\n",
        "        data.append(x[-dim[1]:, :dim[0]])\n",
        "        data.append(x[:dim[1], -dim[0]:])\n",
        "        data.append(x[mid_start_y:mid_start_y+dim[1], mid_start_x:mid_start_x+dim[0]])\n",
        "    del X\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "\n",
        "def predict_ensemble_center(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        print(pred[i:i+5])\n",
        "        softmax = pred[i+4]\n",
        "        print(softmax)\n",
        "        choice = np.argmax(softmax)\n",
        "        results.append(choice)\n",
        "        print(choice)\n",
        "    return results\n",
        "\n",
        "def predict_ensemble_rest(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        softmax = pred[i:i+3]\n",
        "        print(softmax)\n",
        "        total_prob = np.sum(softmax, axis=0)\n",
        "        total_prob /= np.sum(total_prob)\n",
        "        choice = np.argmax(total_prob)\n",
        "        results.append(choice)\n",
        "        print(choice)\n",
        "    return results\n",
        "\n",
        "\n",
        "def predict_ensemble(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        softmax = pred[i:i+5]\n",
        "        total_prob = np.sum(softmax, axis=0)\n",
        "        total_prob /= np.sum(total_prob)\n",
        "        choice = np.argmax(total_prob)\n",
        "        results.append(choice)\n",
        "    return results\n",
        "\n",
        "def predict_ensemble_top(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        softmax = pred[i:i+5]\n",
        "        print(softmax)\n",
        "        top = np.max(softmax, axis=0)\n",
        "        print(top)\n",
        "        choice = np.argmax(top)\n",
        "        results.append(choice)\n",
        "        print(choice)\n",
        "    return results\n",
        "\n",
        "def predict_ensemble_vote(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        softmax = pred[i:i+5]\n",
        "        print(softmax)\n",
        "        votes = np.argmax(softmax, axis=1)\n",
        "        print(votes)\n",
        "        counts = np.bincount(votes)\n",
        "        print(counts)\n",
        "        choice = np.argmax(counts)\n",
        "        results.append(choice)\n",
        "        print(choice)\n",
        "    return results\n",
        "\n",
        "def predict_ensemble_top_3(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        softmax = np.array(pred[i:i+5])\n",
        "        print(softmax)\n",
        "        top_softmax = np.sort(softmax, axis=0)[2:]\n",
        "        print(top_softmax)\n",
        "        total_prob = np.sum(softmax, axis=0)\n",
        "        total_prob /= np.sum(total_prob)\n",
        "        choice = np.argmax(total_prob)\n",
        "        results.append(choice)\n",
        "        print(choice)\n",
        "    return results\n",
        "\n",
        "# def predict_ensemble_top_3(pred, images=None):\n",
        "#     results = []\n",
        "#     for i in range(0, len(pred), 5):\n",
        "#         softmax = np.array(pred[i:i+5]).T\n",
        "#         top_softmax = np.sort(softmax)[2:].T\n",
        "#         print(top_softmax)\n",
        "#         total_prob = np.sum(softmax, axis=0)\n",
        "#         total_prob /= np.sum(total_prob)\n",
        "#         choice = np.argmax(total_prob)\n",
        "#         results.append(choice)\n",
        "#         print(choice)\n",
        "#     return results\n",
        "\n",
        "def predict_ensemble_top_volume(pred, images=None):\n",
        "    results = []\n",
        "    for i in range(0, len(pred), 5):\n",
        "        softmax = np.array(pred[i:i+5])\n",
        "        print(softmax)\n",
        "        top_softmax = np.sort(softmax, axis=0)[3:]\n",
        "        print(top_softmax)\n",
        "        factor = 0\n",
        "        volume = 0\n",
        "        for i in range(5):\n",
        "          for j in range(2):\n",
        "            volume += top_softmax[j][i] * i\n",
        "            factor += top_softmax[j][i]\n",
        "        choice = int(round(volume/factor))\n",
        "        results.append(choice)\n",
        "    return results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH45xCR8WSX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.model.save('./model_tl',  overwrite=True, save_format='tf', include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-jtUyWQXAyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_01_234.model.save('./binary_models/model_01_234',  overwrite=True, save_format='tf')\n",
        "model = tf.keras.models.load_model('./binary_models/model_1_3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBAwmIJKei_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X, Y = helper.aug_by_crop(helper.X_train_images, helper.Y_train, [400, 400], [500, 400, 400, 400, 400])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmJSPKAucdZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1_3.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb8BN6odEyTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6HlGT9rhRNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decide(pred, negative_classes, final_pred):\n",
        "  if len(negative_classes) == 1:\n",
        "    negative_class = negative_classes[0]\n",
        "    for i, p in enumerate(pred):\n",
        "      if p == 0 and type(final_pred[i]).__name__ != 'list' and final_pred[i] == -1:\n",
        "        final_pred[i] = negative_class\n",
        "      elif p == 0 and type(final_pred[i]).__name__ == 'list' and negative_class in final_pred[i]:\n",
        "        final_pred[i] = negative_class\n",
        "  else:\n",
        "    for i, p in enumerate(pred):\n",
        "      if p == 0 and type(final_pred[i]).__name__ != 'list' and final_pred[i] == -1:\n",
        "        final_pred[i] = negative_classes\n",
        "      elif p == 0 and type(final_pred[i]).__name__ == 'list' and all([1 if e in final_pred[i] else 0 for e in negative_classes]):\n",
        "        final_pred[i] = negative_classes\n",
        "  return final_pred\n",
        "\n",
        "def reset_pred(classes, final_pred):\n",
        "  for i, p in enumerate(final_pred):\n",
        "    if p in classes:\n",
        "      final_pred[i] = -1\n",
        "  return final_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2E9Ko0khlYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_01_234 = tf.keras.models.load_model('./binary_models/model_01_234')\n",
        "print(\"loaded\")\n",
        "model_0_1 = tf.keras.models.load_model('./binary_models/model_0_1')\n",
        "print(\"loaded\")\n",
        "model_4_23 = tf.keras.models.load_model('./binary_models/model_4_23')\n",
        "print(\"loaded\")\n",
        "model_3_4 = tf.keras.models.load_model('./binary_models/model_3_4')\n",
        "print(\"loaded\")\n",
        "model_1_23 = tf.keras.models.load_model('./binary_models/model_1_23')\n",
        "print(\"loaded\")\n",
        "model_2_3 = tf.keras.models.load_model('./binary_models/model_2_3')\n",
        "print(\"loaded\")\n",
        "model_1_2 = tf.keras.models.load_model('./binary_models/model_1_2')\n",
        "print(\"loaded\")\n",
        "model_1_3 = tf.keras.models.load_model('./binary_models/model_1_3')\n",
        "print(\"loaded\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljZkVBk29oxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.array(helper.X_test_images)\n",
        "pred_01_234 = np.argmax(model_01_234.predict(X_test), axis=1)\n",
        "pred_0_1 = np.argmax(model_0_1.predict(X_test), axis=1)\n",
        "pred_4_23 = np.argmax(model_4_23.predict(X_test), axis=1)\n",
        "pred_3_4 = np.argmax(model_3_4.predict(X_test), axis=1)\n",
        "pred_1_23 = np.argmax(model_1_23.predict(X_test), axis=1)\n",
        "pred_2_3 = np.argmax(model_2_3.predict(X_test), axis=1)\n",
        "pred_1_2 = np.argmax(model_1_2.predict(X_test), axis=1)\n",
        "pred_1_3 = np.argmax(model_1_3.predict(X_test), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D01QUXJ9hTsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "final_pred = [-1] * X_test.shape[0]\n",
        "\n",
        "final_pred = decide(pred_01_234, [0, 1], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_01_234), [2, 3, 4], final_pred)\n",
        "\n",
        "final_pred = decide(pred_0_1, [0], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_0_1), [1], final_pred)\n",
        "\n",
        "\n",
        "final_pred = decide(pred_4_23, [4], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_4_23), [2], final_pred)\n",
        "\n",
        "final_pred = reset_pred([1, 2, 3], final_pred)\n",
        "\n",
        "final_pred = decide(pred_1_23, [1], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_1_23), [3], final_pred)\n",
        "\n",
        "\n",
        "final_pred = decide(pred_2_3, [2], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_2_3), [3], final_pred)\n",
        "\n",
        "# final_pred = decide(np.logical_not(pred_1_3), [3], final_pred)\n",
        "# final_pred = decide(np.logical_not(pred_1_2), [2], final_pred)\n",
        "# final_pred = decide(pred_1_2, [1], final_pred)\n",
        "# final_pred = decide(pred_1_3, [1], final_pred)\n",
        "\n",
        "\n",
        "\n",
        "final_pred = reset_pred([3, 4], final_pred)\n",
        "final_pred = decide(pred_3_4, [3], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_3_4), [4], final_pred)\n",
        "\n",
        "\n",
        "final_pred = reset_pred([1, 3], final_pred)\n",
        "final_pred = decide(pred_1_3, [1], final_pred)\n",
        "final_pred = decide(np.logical_not(pred_1_3), [1], final_pred)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK9ecot9gg3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final_pred)\n",
        "print(Counter(final_pred))\n",
        "voted_predictions = helper.one_hot_transform(helper.one_hot, final_pred)\n",
        "np.savetxt(\"predict.csv\", voted_predictions, delimiter=\",\", fmt='%i')\n",
        "print(voted_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lpw5rP5nKMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "for i, img in enumerate(X_test):\n",
        "  if final_pred[i] == 3:\n",
        "    plt.figure(dpi=200)\n",
        "    plt.imshow(cv2.cvtColor(X_test[i], cv2.COLOR_BGR2RGB))\n",
        "    plt.title(final_pred[i])\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a49yspL2oAKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_0_selected_indices = np.random.choice(X_0.shape[0], size=50, replace=False)â€©\n",
        "X_0_selected = X_0[X_0_selected_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}